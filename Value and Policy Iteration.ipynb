{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSbzYS58t7oPrCUSMIIoVT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Policy iteration"],"metadata":{"id":"ORxTTtoKWcVT"}},{"cell_type":"code","source":["def policy_iteration(S, A, r, gamma, P):\n","  policy_old = np.zeros(len(S), dtype = 'int') #indexes of actions\n","  while True:\n","    b = np.zeros(len(S))\n","    A_matrix = []\n","    for i in range(len(S)):\n","      action = A[policy_old[i]]\n","      state = int(S[i])\n","      b[i] =  r(state, action)\n","      # print(action, state, b[i])\n","      \n","      A_row = P[policy_old[i]][i]*gamma\n","      A_matrix.append(A_row)\n","\n","\n","    A_matrix = np.identity(len(S)) - A_matrix\n","    A_matrix = np.array(A_matrix)\n","    v = np.linalg.solve(A_matrix, b)\n","    # print(v)\n","\n","    policy_new = np.zeros(len(S), dtype = 'int')\n","    for j in range(len(S)):\n","      rewards_for_action = np.zeros(len(A))\n","\n","      for k in range(len(A)):\n","        state = S[j]\n","        action = A[k]\n","        rewards_for_action[k] = r(state, action) + gamma*np.dot(P[k][j], v)\n","        \n","      policy_new[j] = np.argmax(rewards_for_action)\n","\n","    # print(policy_new)\n","    if sum(policy_new == policy_old) == len(S):\n","      print(\"entered\")\n","      break\n","    \n","    policy_old = policy_new.copy()\n","  \n","  return policy_old"],"metadata":{"id":"LsEI8lKPZNuw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem for Policy Iteration"],"metadata":{"id":"yc6KKuWhsQVG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-c11Qo1dQBVD"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math"]},{"cell_type":"code","source":["def r(s, a):\n","  return s + a*a"],"metadata":{"id":"HFktnsBFQDsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["S = [1, 2, 3]\n","S = np.array(S)\n","A = [1, 2]\n","A = np.array(A)\n","gamma = 0.7"],"metadata":{"id":"9pEV6wj7QILU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["P_one = [[0.1, 0.1, 0.8], \n","         [0.2, 0.3, 0.5], \n","         [0.8, 0.1, 0.1]]\n","P_two = [[0.8, 0.1, 0.1], \n","         [0.6, 0.2, 0.2], \n","         [0.2, 0.1, 0.7]]\n","P = [P_one, P_two]\n","P = np.array(P)"],"metadata":{"id":"rCr-AbhEQOl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.multiply(P[0][0], [1, 2, 3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLGvrs7PTPNb","executionInfo":{"status":"ok","timestamp":1682229756423,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"2d2588ae-1bcf-43f9-a753-4b9d6aa0f062"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.1, 0.2, 2.4])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["policy  = policy_iteration(S, A, r, gamma, P) #policy array gives indexes of actions we need to access A using these indexes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHGKX8Dv3rcD","executionInfo":{"status":"ok","timestamp":1682229756423,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"99ae885f-4b81-4e93-acf5-6ca9500eb163"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["entered\n"]}]},{"cell_type":"code","source":["policy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjhSFWk8s77Y","executionInfo":{"status":"ok","timestamp":1682229756971,"user_tz":-330,"elapsed":555,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"5b6152a7-28b6-432f-df68-43b7248cc98f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Value iteration"],"metadata":{"id":"VwAxKdn_6ilD"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import math"],"metadata":{"id":"E8IgbGhQqz1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# value_old = zeros(length(state_space), 1);\n","value_old = np.zeros((len(S)))\n","value_new = np.zeros(value_old.shape)\n","policy = np.zeros((len(value_old)))"],"metadata":{"id":"b1mCcUjvQlLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["policy.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJmWlw9GR6lg","executionInfo":{"status":"ok","timestamp":1682229756972,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"cece2d7e-42e1-455d-a138-323261b1592d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3,)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["value_new.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTuagY-4SFTq","executionInfo":{"status":"ok","timestamp":1682229756972,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"6bb93b84-f22c-4f91-c38e-b0e8cadf130f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3,)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def value_iteration(S, A, r, gamma, P, tol = 0.01):\n","  value_old = np.zeros((len(S)))\n","  value_new = np.zeros(value_old.shape)\n","\n","  policy = np.zeros((len(value_old)))\n","  # tol = 0.01\n","  i = 0\n","  while True:\n","    # i = i+1\n","    # if i == 3:\n","    #   break\n","    # print(\"value_old\", value_old)\n","    for s in range(len(S)):\n","      reward_for_action = np.zeros((len(A),))\n","      # print(reward_for_action)\n","      for a in range(len(A)):\n","        state = S[s]\n","        action = A[a]\n","        # print(a, reward_for_action[a])\n","        # print(P[a][s])\n","        # print(value_old)\n","        reward_for_action[a] = r(state, action) + gamma*np.dot(P[a][s], value_old)\n","        \n","      # print(f\"reward for action at state {s}:\", reward_for_action)\n","      policy[s] = np.argmax(reward_for_action)\n","      value_new[s] = np.max(reward_for_action)\n","    # print(f\"Value new at {i}:\", value_new)\n","      \n","    if max(value_new - value_old) < tol:\n","      break\n","    value_old = value_new.copy()\n","    # print(value_old)\n","  return value_old"],"metadata":{"id":"-jLzpg5j3rRR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Problem for Value Iteration"],"metadata":{"id":"HlgxuLZxmA0r"}},{"cell_type":"markdown","source":["grid problem\n","\n","0 1 2\n","\n","3 4 5\n","\n","6 7 8"],"metadata":{"id":"gOSCqew_WBSB"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the state space\n","S = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","\n","# Define the action space\n","A = ['up', 'down', 'left', 'right']\n","\n","# Define the reward function\n","def r(s, a):\n","    if s == 8:\n","        return 10\n","    else:\n","        return -1\n","\n","# Define the transition probabilities\n","P = np.zeros((len(A), len(S), len(S)))\n","for i in range(len(S)):\n","    for j in range(len(A)):\n","        if A[j] == 'up':\n","            if i < 3:\n","                P[j,i,i] = 1\n","            else:\n","                P[j,i,i-3] = 1\n","        elif A[j] == 'down':\n","            if i > 5:\n","                P[j,i,i] = 1\n","            else:\n","                P[j,i,i+3] = 1\n","        elif A[j] == 'left':\n","            if i % 3 == 0:\n","                P[j,i,i] = 1\n","            else:\n","                P[j,i,i-1] = 1\n","        elif A[j] == 'right':\n","            if i % 3 == 2:\n","                P[j,i,i] = 1\n","            else:\n","                P[j,i,i+1] = 1\n","# Define the discount factor\n","gamma = 0.9\n","\n","# Set the tolerance level\n","tol = 0.01\n","\n","# Run the value iteration algorithm\n","value_estimates = value_iteration(S, A, r, gamma, P, tol)\n"],"metadata":{"id":"75yh2-wwldVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["value_estimates.reshape((3,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8W14ydDVf1D","executionInfo":{"status":"ok","timestamp":1682229756973,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vikram Ganesh","userId":"17596391029888008717"}},"outputId":"9209de5b-412a-454f-c64f-d5c339d24687"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[62.0754995, 70.0944995, 79.0044995],\n","       [70.0944995, 79.0044995, 88.9044995],\n","       [79.0044995, 88.9044995, 99.9044995]])"]},"metadata":{},"execution_count":24}]}]}